<!DOCTYPE html><html lang="kr"><head><meta charSet="utf-8"/><link rel="preload" as="font" href="/_next/static/media/e4af272ccee01ff0-s.p.woff2" crossorigin="" type="font/woff2"/><link rel="stylesheet" href="/_next/static/css/e124e0da229202d9.css" data-precedence="next"/><link rel="preload" href="/_next/static/chunks/webpack-c62b9263dde95db3.js" as="script"/><link rel="preload" href="/_next/static/chunks/fd9d1056-5fc0659828b82348.js" as="script"/><link rel="preload" href="/_next/static/chunks/596-5f69a5936ae99734.js" as="script"/><link rel="preload" href="/_next/static/chunks/main-app-e8cf5a024458e18b.js" as="script"/><title>GPT은 직접 사드세요... 제발 - GPT 2</title><meta name="description" content="로또 번호 자판기 모델 구현, 학습, 결과"/><meta name="viewport" content="width=device-width, initial-scale=1"/><meta name="google-site-verification" content="LXzAKbA2-HVF1l60gXdTElFNxVVLxh1rk6qwe1V41so"/><link rel="icon" href="/favicon.ico" type="image/x-icon" sizes="16x16"/><meta name="next-size-adjust"/><script src="/_next/static/chunks/polyfills-78c92fac7aa8fdd8.js" noModule=""></script></head><body class="__className_f367f3"><noscript><iframe src="https://www.googletagmanager.com/ns.html?id=GTM-WNZJJHJW" height="0" width="0" style="display:none;visibility:hidden"></iframe></noscript><div class="w-full flex flex-col items-center p-3"><header class="w-full max-w-3xl flex flex-row justify-between items-center my-1"><a class="flex flex-row items-center" href="/"><img alt="로고" loading="lazy" width="30" height="30" decoding="async" data-nimg="1" class="rounded-full" style="color:transparent" src="/logo.png"/><span class="mx-2 font-semibold text-lg">jiohh blog</span></a><nav><a class="mr-5 " href="/">Home</a><a class="mr-5 " href="/blog">Blog</a><a class="mr-5 " href="/category">Category</a></nav></header><main class="w-full max-w-3xl"><div class="mt-10 prose"><h1 class="">GPT은 직접 사드세요... 제발 - GPT 2</h1><img src="/images/LLM/gpt_thumbnail.png" width="100%" height="100%"/>
<p>(AI를 잘모르는 백엔드 엔지니어 수준으로 진행한 후 프로젝트입니다.)</p>
<h4>GPT은 직접 사드세요... 제발</h4>
<ul>
<li><a href="https://an-jiohh.github.io/blog/LLMgpt1">특정 기능 수행 모델까지의 여정</a></li>
<li><a href="https://an-jiohh.github.io/blog/LLMgpt2">로또 번호 자판기 모델 구현, 학습, 결과</a> ⬅️ 현재글</li>
<li><a href="https://an-jiohh.github.io/blog/LLMgpt3">후기(작성 예정)</a></li>
</ul>
<hr/>
<h2>개요</h2>
<ol>
<li>데이터 생성</li>
<li>모델 Pre-training</li>
<li>n차 개선 학습</li>
<li>모델 테스트</li>
</ol>
<p>현재 글에서 모델을 구현하는데 고민하였던 여러 사항들을 간단하게 이야기하고 결과를 확인해보고자 한다.</p>
<hr/>
<h2>데이터 생성</h2>
<h3>입출력 형식 정의</h3>
<p>이미 로또 미션을 진행해본 상황으로 입출력 형태의 정의는 잡혀있는 상태이다.</p>
<pre><code>구입금액을 입력해 주세요.
8000

8개를 구매했습니다.
[8, 21, 23, 41, 42, 43]
[3, 5, 11, 16, 32, 38]
[7, 11, 16, 35, 36, 44]
[1, 8, 11, 31, 41, 42]
[13, 14, 16, 38, 42, 45]
[7, 11, 30, 40, 42, 43]
[2, 13, 22, 32, 38, 45]
[1, 3, 5, 14, 22, 45]

당첨 번호를 입력해 주세요.
1,2,3,4,5,6

보너스 번호를 입력해 주세요.
7

당첨 통계
---
3개 일치 (5,000원) - 1개
4개 일치 (50,000원) - 0개
5개 일치 (1,500,000원) - 0개
5개 일치, 보너스 볼 일치 (30,000,000원) - 0개
6개 일치 (2,000,000,000원) - 0개
총 수익률은 62.5%입니다.
</code></pre>
<p>다만 다음과 같이 입출력이 섞여있는 형태이다.</p>
<ol>
<li>구입금액 입력</li>
<li>구입갯수 출력</li>
<li>생성된 번호 출력</li>
<li>당첨 번호 입력</li>
<li>...</li>
</ol>
<p>LLM 특성상 인풋 -&gt; 아웃풋으로 출력되기 때문에 입출력의 용이성을 위해 입출력 형식의 개선이 필요했다.</p>
<pre><code>&lt;IN&gt;
구입금액={money}
당첨번호={w1,w2,w3,w4,w5,w6}
보너스번호={bonus}
&lt;/IN&gt;
###
&lt;OUT&gt;
티켓수={ticket_count}
구매번호:
{ticket1}
{ticket2}
...
3개일치={count3}
4개일치={count4}
5개일치={count5}
5개보너스일치={count5b}
6개일치={count6}
수익률={rate}%
&lt;/OUT&gt;
</code></pre>
<p>따라서 다음과 같은 형태로 입출력 형태를 재정의 하였다.<br/>
<!-- -->또한 ### 구분자를 추가하여 입력과 출력을 구분하였다.</p>
<p>다만 추가 특이사항으로
예외에 대한 처리는 데이터 셋에서 제외하였다.<br/>
<!-- -->학습시간을 최소화하는 것이 가장 큰 관건이라고 생각하였고 가설이 검증될 경우 예외 케이스 추가 및 추가학습으로 예외처리 사항도 가능할 것이라고 예상 했기 때문이다.</p>
<h3>데이터 셋은 얼마나 필요할까?</h3>
<ul>
<li>디버그/프로토타입용: 5k–10k 샘플</li>
<li>실험/논문화 가능한 최소선: 20k–50k 샘플</li>
<li>충분히 안정적인 학습: 50k–100k 샘플</li>
</ul>
<p>정도로 기준점을 마련한 후 가장 작은 단위부터 진행하는 것이
학습 시간 고려, 잘못된 데이터셋 개선, 모델 구조 개선 측면에서 좋다고 판단하였다.</p>
<p>토큰 수를 계산해 보았을때</p>
<pre><code>money=8000            ( ~ 12자 )
winning=1,2,3,4,5,6   ( ~ 20자 )
bonus=7               ( ~ 8자 )
###                   ( ~ 3자 )
티켓수=8              ( ~ 6자 )
구매번호:             ( ~ 5자 )
[8,21,23,41,42,43]    ( ~ 18자 )  × 티켓수(최대 20개라 쳐도 평균 10개 미만)
...
3개일치=1             ( ~ 8자 ) × 5줄
수익률=62.5%          ( ~ 10자 )
</code></pre>
<p>샘플 하나당 200~400글자로 예상하였고</p>
<ul>
<li>10k 샘플 → 약 2M–4M 토큰</li>
<li>50k 샘플 → 약 10M–20M 토큰</li>
<li>100k 샘플 → 약 20M–40M 토큰</li>
</ul>
<p>각 샘플당 이러한 토큰 수를 가지게 된다.</p>
<hr/>
<h2>모델 Pre-training</h2>
<h4>토크나이저 선정</h4>
<p>기본적으로 많이 사용하는 토크나이저 중 각각 장단점 비교 후 선택하였다.<br/>
<!-- -->출력에 한국어가 사용되기 때문에 한국어 토크나이저를 기준으로 비교하여 선택하였다.</p>
<ol>
<li>
<p><strong>GPT-2</strong><br/>
<!-- -->한글, 숫자, 기호, 줄바꿈 모두 안정적으로 처리<br/>
<!-- -->미니 모델 적절한 토큰 수</p>
</li>
<li>
<p><strong>skt/kogpt2-base-v2</strong><br/>
<!-- -->한국어 SentencePiece 기반 → 한글 처리 매우 안정적<br/>
<!-- -->vocab_size 약 51k → GPT2와 비슷</p>
</li>
<li>
<p><strong>EXAONE tokenizer (LGAI-EXAONE/ExaOne-3.5-7.8B-Instruct)</strong>
한국어 특화에서 가장 좋은 성능을 보임
vocab_size 약 500k</p>
</li>
</ol>
<p>최종적으로는 GPT-2를 그대로 사용하였는데 이유는 다음과 같았다.</p>
<ul>
<li>GPT-2<br/>
<!-- -->기존에 만들어봤던 모델에서 사용했기 때문에 시행착오가 적을 것으로 판단</li>
<li>skt/kogpt2-base-v2<br/>
<!-- -->데이터 셋 특성상 특수 문자 패턴이 반복되는 로또 데이터에서는 GPT2 tokenizer와 큰 차이 없음<br/>
<!-- -->굳이 가중치가 조금 더 흔들려있는 KoGPT2를 사용해야 할까라는 의문점</li>
<li>EXAONE tokenizer (LGAI-EXAONE/ExaOne-3.5-7.8B-Instruct)<br/>
<!-- -->vocab_size 약 500k 엄청 큼 → 과도한 vocab 규모라고 판단하여 사용 X</li>
</ul>
<h4>pad_token 설정</h4>
<p>LLM은 batch 단위로 학습하며 지정한 max_len=256이라면 모든 문장은 길이가 정확히 256토큰이여야한다.</p>
<p>이전 해리포터 모델과는 다르게 로또 생성기의 경우에는 끝나는 지점이 정해져 있다. 그렇기 때문에 모든 문장의 길이가 동일할 수는 없다.</p>
<ul>
<li>해리포터 모델<br/>
<!-- -->Dobby is a가 입력으로 주어지면 책이 끝나는 부분이 아니라면 계속해서 일졍한 부분을 채우게된다.</li>
<li>로또 자판기
수익률=11.1% 출력되었다면 이 다음에 출력할 부분은 없음</li>
</ul>
<p>따라서 나머지 부분을 채우기 위해 pad_token이란 것을 사용하게 된다.</p>
<h4>모델 구조 선정</h4>
<p>이 부분에서 많은 내용이 있어야하지만 크게 변경된 사항은 없이 이전 구조를 사용하였다.</p>
<p>즉, GPT-2 논문 트랜스포머 블록 구조랑 거의 동일하게 사용하였는데
아직 추가적인 지식에 대한 학습이 필요한 부분이기도하고, 간단한 모델에서 시작해서 추가적인 사항을 추가하는 것이 중요하다고 판단하였기 때문이였다.</p>
<h4>학습</h4>
<p>epoch 30으로 진행하였고, RTX 4060을 사용하여 8시간 정도 소요 되었다.</p>
<pre><code>[Epoch 001] train_loss=1.3327, val_loss=0.9760
[Epoch 002] train_loss=1.1994, val_loss=0.9647
[Epoch 003] train_loss=1.0896, val_loss=0.9421
...
[Epoch 028] train_loss=0.7817, val_loss=0.7795
[Epoch 029] train_loss=0.7805, val_loss=0.7783
[Epoch 030] train_loss=0.7798, val_loss=0.7781
</code></pre>
<p>loss 또한 꾸준히 하락하였고 과적합 또한 보이지 않았다.</p>
<h4>결과</h4>
<img src="/images/LLM/result1-1.png" width="100%" height="100%"/>
<img src="/images/LLM/result1-2.png" width="100%" height="100%"/>
<p>어느 정도 형태를 띄는 긍정적인 결과값을 확인할 수 있었다 !!</p>
<p>입력된 금액을 바탕으로
티켓수, 구매번호를 갯수에 맞게 출력했고 n개 일치 항목, 수익률 항목에 대해 형식을 잘 출력하는 것을 볼 수 있다.</p>
<hr/>
<h2>n차 개선 학습</h2>
<h3>1차 모델 개선</h3>
<h4>1. repetition loop</h4>
<p>수익률 부분에서 출력값이 이상한 것을 확인할 수 있었다.</p>
<p><strong>수익률 =0.0%%%%%%%%%%%%%%%</strong></p>
<p>마지막에 %이 계속해서 반복되며 출력되는 현상으로 멈춰야하는 신호를 주지않았기 때문에 발생한 문제</p>
<p>멈춤 신호인 EOS토큰을 stop 조건으로 안쓰지 않았고 학습과정에서 eos 토큰을 따로 붙여준 적이 없었기 때문에
데이터셋을 로드하는 LottoDataset 객체를 수정하여 마지막에 eos토큰이 추가되도록 수정하였다.</p>
<p>(EOS 토큰 부분에서 모델학습만 3~4번 반복하였는데 기존 코드를 삭제하지 않아 누락되었던 것은 비밀...)</p>
<h4>2. 출력값 제한으로 인한 짤림 문제</h4>
<p>max_len을 256으로 설정하여 진행하였는데 입력 금액이 많아질 경우 출력 토큰 제한으로 출력이 짤리는 문제가 발생하였다.</p>
<pre><code>money=18000
winning=1,2,3,4,5,6
...
[4,20,22,32,39,40]
[11,13,20
</code></pre>
<p>이런식으로 마지막 부분이 짤려 정상적인 출력이 되지않는 상황이였다.<br/>
<!-- -->max_len은 학습시간과 연관이 있어 무제한으로 키우기는 어려우니 최소 상한 금액을 20000원으로 가정하고
max_len을 512로 수정하여 진행하였다.</p>
<p>max_len=256<br/>
<!-- -->→ 총 토큰 = 10,000 × 256 = 2.56M tokens</p>
<p>max_len=512<br/>
<!-- -->→ 총 토큰 = 10,000 × 512 = 5.12M tokens</p>
<p>토큰 수 변화가 2배로 뛰게 되었다.</p>
<h4>2-1. 출력값 증가로 인한 메모리 부족현상 발생</h4>
<p>출력값이 두배로 뛰면서 input으로 사용되는 데이터 크기 또한 두배로 커졌고 이에 따라 GPU의 메모리에서 OOM이 발생하는 현상이 발생하였다.</p>
<p>GPU 메모리 한계를 극복하기 위해 Gradient Accumulation를 적용하여 자원의 한계를 해결하고자 하였다.</p>
<p>Gradient Accumulation는 간단하게 기존 배치를 작은 배치(학습단위)로 줄인 후 작은 배치에서 계산된 loss를 누적하여
정해진 횟수에 도달할 경우 그때 가중치를 업데이트하는 방식이다.</p>
<p>기존 batch size = 32 -&gt; batch size = 8, accum_steps = 4로 수정하여<br/>
<!-- -->(batch 8 * 4 = effective 32) 기존의 32 batch와 동일한 효과를 낼 수 있도록 수정하였다.</p>
<h3>2차 모델 개선</h3>
<p>2차 부터는 각 기능이 제대로 동작하는가를 체크하였다.</p>
<h4>1. 당첨번호 계산 과적합 문제 해결</h4>
<pre><code>money=5000
winning=1,2,3,4,5,6
bonus=7
...
[4,5,6,25,27,44]
3개일치=0
</code></pre>
<p>n개 일치 항목에 대해 카운트가 잘 되지않는 현상이였다.
모든 간이 테스트에서 일치하는 항목이 나오지 않았다.</p>
<p>로또의 확률을 생각해보면 그 답을 알 수 있었는데, 로또 번호는 기본적으로 당첨 확률이 굉장히 낮은 분포를 보인다.<br/>
<!-- -->이 때문에 n개 일치 항목에 대한 데이터셋에는 일치 항목이 0인 데이터셋이 많아지게된다.</p>
<p>즉 많은 데이터가 일치항목에서 0을 띄기 때문에 gpt는 해당 패턴을 기준으로 0이 정답이라는 기준을 세우게 되는 것이다.
(값이 있더라도 loss가 낮기 때문에 해당 부분이 무시되게됨)<br/>
<!-- -->일치 항목에 대해서 0에 과적합이 되는 것이다.</p>
<p>이를 해결하기 위해 데이터셋 생성 부분에서 일정한 비율로 당첨번호가 꼭 나오도록 생성에 대한 조건을 추가하여 학습하였다.</p>
<pre><code>FORCE_HIT_PROB = 0.3 # 당첨 비율 설정(30%)
if random.random() &lt; FORCE_HIT_PROB and ticket_count &gt; 0:
    # 어떤 등수를 넣을지 가중치로 선택
    rank_candidates = [&quot;3&quot;, &quot;4&quot;, &quot;5&quot;, &quot;5b&quot;, &quot;6&quot;]
    # 3개/4개 정도를 많이, 5/5b/6은 조금만
    rank_weights = [0.4, 0.2, 0.2, 0.1, 0.1]
    rank = random.choices(rank_candidates, weights=rank_weights, k=1)[0]

    # 티켓 중 하나 골라서 그 자리를 &quot;해당 등수 티켓&quot;으로 바꿈
    idx = random.randrange(ticket_count)
    tickets[idx] = generate_ticket_with_rank(winning, bonus, rank)
</code></pre>
<h4>2. 수익률 부분 추가 데이터 제공</h4>
<p>수익률 또한 높은 확률로 계산하지 못하였는데 너무나 근거없는 수치가 나오는 경우의 수가 많았다.</p>
<p>데이터 셋을 확인하였을때 수익률 계산에 대한 근거가 부족하다는 생각이 들었다.</p>
<pre><code>3개일치={count3}
4개일치={count4}
5개일치={count5}
5개보너스일치={count5b}
6개일치={count6}
수익률={rate}%
</code></pre>
<p>지금 형태는 이런 형태인데 n개 일치에 따라서 따라오는 금액이 얼마인지 데이터셋에서 찾기 힘들었다.<br/>
<!-- -->따라서 일치시 얻게되는 금액을 추가하여 gpt가 해당 금액을 계산(패턴학습)할 수 있도록 추가하였다.</p>
<pre><code>3개일치 (5000원) = 0
4개일치 (50000원) = 0
5개일치 (1500000원) = 0
5개보너스일치 (30000000원) = 0
6개일치 (2000000000원) = 0
수익률=0.0%
</code></pre>
<h3>3차 모델 개선</h3>
<p>수익률 부분에서는 높은 일치율을 보였지만 당첨번호 계산 부분에서는 아직도 낮은 일치율을 보였다.</p>
<p><strong>Task-Aware Weighted Loss</strong>, <strong>Token-level Weighting</strong>,<strong>Curriculum by Masking</strong>
으로 불리는 어려운 부분에 가중치를 더욱 크게 부여하는 것이 해결책으로 판단하였다.</p>
<p>즉 loss를 보았을때 감소하는 추세이나 모든 토큰이 똑같이 1.0의 가중치로 loss에 들어가기 떄문에
똑같은 가중치로 하였을때 정해져있는 포맷부분(money=, winning=, 숫자 쉼표, 티켓수= 등)은 잘맞추어 loss가 떨어지고
마지막인 당첨갯수, 수익률 부분은 대충 때려맞추고 있어도 loss에 반영되지 않은 현상이 발생하는 것으로 예상하였다.</p>
<p>따라서 모델 구성을 변경하여 마지막 tail_len을 계산후 지정하여 해당 부분이 더 높은 가중치를 가지도록 변경하였다.</p>
<h3>4차 모델 개선</h3>
<p>당첨번호 계산 부분에서 추가적인 효과가 없어 데이터 셋의 크기를 늘려 추가적인 학습이 반영되도록 개선하였다.</p>
<ul>
<li>10k 샘플 → 약 2M–4M 토큰</li>
<li>50k 샘플 → 약 10M–20M 토큰</li>
<li>150k 샘플 → 약 40M–60M 토큰</li>
</ul>
<p>학습량을 지속적으로 늘려 진행했고 그 과정 속에서 기능이 동작하는지 확인하였으나 큰 효과를 얻기는 어려웠다.</p>
<hr/>
<h2>모델 테스트</h2>
<h3>테스트 정의</h3>
<p>기존 LLm을 테스트하기 위해 여러 방법이 있는 것으로 알고 있다.</p>
<ul>
<li>MMLU</li>
<li>KMMLU</li>
<li>HAERAE</li>
<li>HumanEval</li>
<li>MBPP</li>
<li>GSM8K</li>
</ul>
<p>다만 프로그래밍적인 요소, 출력 형태의 고정으로 새로운 테스트를 정의해야한다고 생각하였다.</p>
<p>출력한 형태와 기능을 만족하는가 두가지를 기준으로 테스트 기준을 재설정하였다.</p>
<h4>1. 형식/파싱 레벨</h4>
<p><strong>1-1. 티켓수 형식</strong></p>
<ul>
<li>티켓수 = N 이 존재하는지</li>
<li>N이 정수로 파싱되는지</li>
</ul>
<p><strong>1-2. 구매번호 줄 형식</strong></p>
<ul>
<li>구매번호: 라인이 존재하는지</li>
<li>그 아래에 [...] 형태의 줄들이 있는지</li>
<li>각 줄에서 숫자를 파싱할 수 있는지</li>
</ul>
<p><strong>1-3. 라벨(결과) 줄 형식</strong></p>
<ul>
<li>아래 항목이 모두 존재하고 숫자로 파싱되는지<!-- -->
<ul>
<li>3개일치 (...) = X</li>
<li>4개일치 (...) = Y</li>
<li>5개일치 (...) = Z</li>
<li>5개보너스일치 (...) = A</li>
<li>6개일치 (...) = B</li>
<li>수익률 = R%</li>
</ul>
</li>
</ul>
<h4>2. 내부 일관성 레벨</h4>
<p><strong>2-1. 티켓수 일관성</strong></p>
<ul>
<li>티켓수 = 실제 구매번호 줄 개수가 같은지</li>
</ul>
<p><strong>2-2. 구매번호 자체 유효성</strong></p>
<ul>
<li>각 줄에 숫자가 정확히 6개인지</li>
<li>한 줄 안에 중복 숫자가 없는지</li>
<li>각 숫자가 1~45 범위인지</li>
</ul>
<h2>3. 계산 정확도 레벨 (기능 테스트)</h2>
<p>LLM 출력에 적힌 “결과 값들”이, 그 LLM이 출력한 “구매번호”로 실제 계산했을 때 맞는지.</p>
<p><strong>3-1. n개 일치 수 계산 검증</strong></p>
<ul>
<li>구매번호 기반으로 다시 3/4/5/5b/6개 일치 개수를 계산</li>
<li>그 값이 LLM이 쓴 X, Y, Z, A, B와 각각 일치하는지</li>
</ul>
<p><strong>3-2. 수익률 계산 검증</strong></p>
<ul>
<li>이 값이 LLM이 쓴 수익률 = 실제 수익율</li>
</ul>
<h3>테스트 결과</h3>
<pre><code>=== TEST SUMMARY ===
n_total : 5000
n_ok : 2298 (성공)
n_fail : 2702 (실패)

n_format_fail : 293 (형식표현 실패)
n_logic_fail : 2409 (기능구현 실패)

ticket_count_parse_error : 0
ticket_lines_format_error : 2
result_labels_parse_error : 11
ticket_count_mismatch : 35
ticket_numbers_invalid : 245

match_stats_mismatch : 2408
roi_mismatch : 17
test_fail : 0
</code></pre>
<h4>출력 형식 오류 분석</h4>
<p>n_format_fail : 텍스트 출력 구조 문제<br/>
<!-- -->5000중 293건 → 형식 안정도 94%</p>
<p><code>n_format_fail</code>에러 항목</p>
<ul>
<li>ticket_count_parse_error<br/>
<code>티켓:숫자</code> 항목이 형식대로 출력되는가</li>
<li>ticket_lines_format_error<br/>
<code>구매번호:</code> 라인이 존재하는지
하위의 <code>구매번호: [:]</code> 생선된 구매번호 형식에 맞게 출력되었는지</li>
<li>result_labels_parse_error<br/>
<code>n개일치: ~ 수익률:</code>의 항목이 형식대로 출력되는가</li>
<li>ticket_count_mismatch
<code>구매한티켓수 = 구매번호의 티켓수</code> , 실제로 금액만큼 티켓을 구매하였는가</li>
<li>ticket_numbers_invalid
<code>구매번호</code>가 올바른 형식인가(중복 X, 1~45)</li>
</ul>
<p>각 항목에서 발생된 결과는 다음과 같다.</p>
<ul>
<li>format_fail : 293건, 5.86%</li>
<li>lines error : 2건, 0.04%</li>
<li>label parse error : 11건,	0.22%</li>
<li>ticket_count_mismatch	: 35건, 0.70%</li>
<li>ticket_numbers_invalid : 245건, 4.90%</li>
</ul>
<h4>기능 구현 오류 분석</h4>
<p>n_logic_fail : 기능 구현 오류
5000중 2409건 → 안정도 55%</p>
<p>match_stats_mismatch : 2408<br/>
<!-- -->그중 당첨번호 일치가 대분을 차지하는 모습을 보였음</p>
<p>n_logic_fail ≈ match_stats_mismatch 인 상황으로 수익률 부분 계산 부분은 0.34% 에러율을 보이며 매우 낮은 수치를</p>
<p>출력 포맷의 안정성과 수익률 수치 예측은 높은 정확도를 보였으나, 집합 비교 기반 연산 문제에서는 기능 구현 부분에서의 한계를 확인할 수 있었다.</p></div></main><footer class="w-full max-w-3xl items-center "><div class="h-28"></div> </footer></div><script src="/_next/static/chunks/webpack-c62b9263dde95db3.js" async=""></script><script src="/_next/static/chunks/fd9d1056-5fc0659828b82348.js" async=""></script><script src="/_next/static/chunks/596-5f69a5936ae99734.js" async=""></script><script src="/_next/static/chunks/main-app-e8cf5a024458e18b.js" async=""></script><script>(self.__next_f=self.__next_f||[]).push([0])</script><script>self.__next_f.push([1,"1:HL[\"/_next/static/media/e4af272ccee01ff0-s.p.woff2\",{\"as\":\"font\",\"type\":\"font/woff2\"}]\n2:HL[\"/_next/static/css/e124e0da229202d9.css\",{\"as\":\"style\"}]\n0:\"$L3\"\n"])</script><script>self.__next_f.push([1,"4:I{\"id\":7948,\"chunks\":[\"272:static/chunks/webpack-c62b9263dde95db3.js\",\"971:static/chunks/fd9d1056-5fc0659828b82348.js\",\"596:static/chunks/596-5f69a5936ae99734.js\"],\"name\":\"default\",\"async\":false}\n6:I{\"id\":6628,\"chunks\":[\"272:static/chunks/webpack-c62b9263dde95db3.js\",\"971:static/chunks/fd9d1056-5fc0659828b82348.js\",\"596:static/chunks/596-5f69a5936ae99734.js\"],\"name\":\"\",\"async\":false}\n7:I{\"id\":6685,\"chunks\":[\"685:static/chunks/685-1c7543f9470b706b.js\",\"222:static/chunks/222-846c3dee61afe17f.js\",\"404:static"])</script><script>self.__next_f.push([1,"/chunks/app/blog/page-2b1879a4b7dd3b5f.js\"],\"name\":\"\",\"async\":false}\n8:I{\"id\":3222,\"chunks\":[\"685:static/chunks/685-1c7543f9470b706b.js\",\"222:static/chunks/222-846c3dee61afe17f.js\",\"404:static/chunks/app/blog/page-2b1879a4b7dd3b5f.js\"],\"name\":\"Image\",\"async\":false}\n9:I{\"id\":7767,\"chunks\":[\"272:static/chunks/webpack-c62b9263dde95db3.js\",\"971:static/chunks/fd9d1056-5fc0659828b82348.js\",\"596:static/chunks/596-5f69a5936ae99734.js\"],\"name\":\"default\",\"async\":false}\na:I{\"id\":7920,\"chunks\":[\"272:static/chunks/webpa"])</script><script>self.__next_f.push([1,"ck-c62b9263dde95db3.js\",\"971:static/chunks/fd9d1056-5fc0659828b82348.js\",\"596:static/chunks/596-5f69a5936ae99734.js\"],\"name\":\"default\",\"async\":false}\n"])</script><script>self.__next_f.push([1,"3:[[[\"$\",\"link\",\"0\",{\"rel\":\"stylesheet\",\"href\":\"/_next/static/css/e124e0da229202d9.css\",\"precedence\":\"next\"}]],[\"$\",\"$L4\",null,{\"buildId\":\"GbToePPZqnFU5itfcWlmW\",\"assetPrefix\":\"\",\"initialCanonicalUrl\":\"/blog/LLMgpt2\",\"initialTree\":[\"\",{\"children\":[\"blog\",{\"children\":[[\"slug\",\"LLMgpt2\",\"d\"],{\"children\":[\"__PAGE__?{\\\"slug\\\":\\\"LLMgpt2\\\"}\",{}]}]}]},\"$undefined\",\"$undefined\",true],\"initialHead\":\"$L5\",\"globalErrorComponent\":\"$6\",\"children\":[null,[\"$\",\"html\",null,{\"lang\":\"kr\",\"children\":[null,[\"$\",\"body\",null,{\"className\":\"__className_f367f3\",\"children\":[[\"$\",\"noscript\",null,{\"children\":[\"$\",\"iframe\",null,{\"src\":\"https://www.googletagmanager.com/ns.html?id=GTM-WNZJJHJW\",\"height\":\"0\",\"width\":\"0\",\"style\":{\"display\":\"none\",\"visibility\":\"hidden\"}}]}],[\"$\",\"div\",null,{\"className\":\"w-full flex flex-col items-center p-3\",\"children\":[null,[\"$\",\"header\",null,{\"className\":\"w-full max-w-3xl flex flex-row justify-between items-center my-1\",\"children\":[[\"$\",\"$L7\",null,{\"href\":\"/\",\"className\":\"flex flex-row items-center\",\"children\":[[\"$\",\"$L8\",null,{\"src\":\"/logo.png\",\"alt\":\"로고\",\"width\":30,\"height\":30,\"objectFit\":\"cover\",\"className\":\"rounded-full\"}],[\"$\",\"span\",null,{\"className\":\"mx-2 font-semibold text-lg\",\"children\":\"jiohh blog\"}]]}],[\"$\",\"nav\",null,{\"children\":[[\"$\",\"$L7\",\"Home\",{\"href\":\"/\",\"className\":\"mr-5 \",\"children\":\"Home\"}],[\"$\",\"$L7\",\"Blog\",{\"href\":\"/blog\",\"className\":\"mr-5 \",\"children\":\"Blog\"}],[\"$\",\"$L7\",\"Category\",{\"href\":\"/category\",\"className\":\"mr-5 \",\"children\":\"Category\"}]]}]]}],[\"$\",\"main\",null,{\"className\":\"w-full max-w-3xl\",\"children\":[\"$\",\"$L9\",null,{\"parallelRouterKey\":\"children\",\"segmentPath\":[\"children\"],\"error\":\"$undefined\",\"errorStyles\":\"$undefined\",\"loading\":\"$undefined\",\"loadingStyles\":\"$undefined\",\"hasLoading\":false,\"template\":[\"$\",\"$La\",null,{}],\"templateStyles\":\"$undefined\",\"notFound\":[[\"$\",\"title\",null,{\"children\":\"404: This page could not be found.\"}],[\"$\",\"div\",null,{\"style\":{\"fontFamily\":\"system-ui,\\\"Segoe UI\\\",Roboto,Helvetica,Arial,sans-serif,\\\"Apple Color Emoji\\\",\\\"Segoe UI Emoji\\\"\",\"height\":\"100vh\",\"textAlign\":\"center\",\"display\":\"flex\",\"flexDirection\":\"column\",\"alignItems\":\"center\",\"justifyContent\":\"center\"},\"children\":[\"$\",\"div\",null,{\"children\":[[\"$\",\"style\",null,{\"dangerouslySetInnerHTML\":{\"__html\":\"body{color:#000;background:#fff;margin:0}.next-error-h1{border-right:1px solid rgba(0,0,0,.3)}@media (prefers-color-scheme:dark){body{color:#fff;background:#000}.next-error-h1{border-right:1px solid rgba(255,255,255,.3)}}\"}}],[\"$\",\"h1\",null,{\"className\":\"next-error-h1\",\"style\":{\"display\":\"inline-block\",\"margin\":\"0 20px 0 0\",\"padding\":\"0 23px 0 0\",\"fontSize\":24,\"fontWeight\":500,\"verticalAlign\":\"top\",\"lineHeight\":\"49px\"},\"children\":\"404\"}],[\"$\",\"div\",null,{\"style\":{\"display\":\"inline-block\"},\"children\":[\"$\",\"h2\",null,{\"style\":{\"fontSize\":14,\"fontWeight\":400,\"lineHeight\":\"49px\",\"margin\":0},\"children\":\"This page could not be found.\"}]}]]}]}]],\"notFoundStyles\":\"$undefined\",\"childProp\":{\"current\":[\"$\",\"$L9\",null,{\"parallelRouterKey\":\"children\",\"segmentPath\":[\"children\",\"blog\",\"children\"],\"error\":\"$undefined\",\"errorStyles\":\"$undefined\",\"loading\":\"$undefined\",\"loadingStyles\":\"$undefined\",\"hasLoading\":false,\"template\":[\"$\",\"$La\",null,{}],\"templateStyles\":\"$undefined\",\"notFound\":\"$undefined\",\"notFoundStyles\":\"$undefined\",\"childProp\":{\"current\":[\"$\",\"$L9\",null,{\"parallelRouterKey\":\"children\",\"segmentPath\":[\"children\",\"blog\",\"children\",[\"slug\",\"LLMgpt2\",\"d\"],\"children\"],\"error\":\"$undefined\",\"errorStyles\":\"$undefined\",\"loading\":\"$undefined\",\"loadingStyles\":\"$undefined\",\"hasLoading\":false,\"template\":[\"$\",\"$La\",null,{}],\"templateStyles\":\"$undefined\",\"notFound\":\"$undefined\",\"notFoundStyles\":\"$undefined\",\"childProp\":{\"current\":[\"$Lb\",[\"$\",\"div\",null,{\"className\":\"mt-10 prose\",\"children\":[[\"$\",\"h1\",null,{\"className\":\"\",\"children\":\"GPT은 직접 사드세요... 제발 - GPT 2\"}],[[\"$\",\"img\",null,{\"src\":\"/images/LLM/gpt_thumbnail.png\",\"width\":\"100%\",\"height\":\"100%\"}],\"\\n\",[\"$\",\"p\",null,{\"children\":\"(AI를 잘모르는 백엔드 엔지니어 수준으로 진행한 후 프로젝트입니다.)\"}],\"\\n\",[\"$\",\"h4\",null,{\"children\":\"GPT은 직접 사드세요... 제발\"}],\"\\n\",[\"$\",\"ul\",null,{\"children\":[\"\\n\",[\"$\",\"li\",null,{\"children\":[\"$\",\"a\",null,{\"href\":\"https://an-jiohh.github.io/blog/LLMgpt1\",\"children\":\"특정 기능 수행 모델까지의 여정\"}]}],\"\\n\",[\"$\",\"li\",null,{\"children\":[[\"$\",\"a\",null,{\"href\":\"https://an-jiohh.github.io/blog/LLMgpt2\",\"children\":\"로또 번호 자판기 모델 구현, 학습, 결과\"}],\" ⬅️ 현재글\"]}],\"\\n\",[\"$\",\"li\",null,{\"children\":[\"$\",\"a\",null,{\"href\":\"https://an-jiohh.github.io/blog/LLMgpt3\",\"children\":\"후기(작성 예정)\"}]}],\"\\n\"]}],\"\\n\",[\"$\",\"hr\",null,{}],\"\\n\",[\"$\",\"h2\",null,{\"children\":\"개요\"}],\"\\n\",[\"$\",\"ol\",null,{\"children\":[\"\\n\",[\"$\",\"li\",null,{\"children\":\"데이터 생성\"}],\"\\n\",[\"$\",\"li\",null,{\"children\":\"모델 Pre-training\"}],\"\\n\",[\"$\",\"li\",null,{\"children\":\"n차 개선 학습\"}],\"\\n\",[\"$\",\"li\",null,{\"children\":\"모델 테스트\"}],\"\\n\"]}],\"\\n\",[\"$\",\"p\",null,{\"children\":\"현재 글에서 모델을 구현하는데 고민하였던 여러 사항들을 간단하게 이야기하고 결과를 확인해보고자 한다.\"}],\"\\n\",[\"$\",\"hr\",null,{}],\"\\n\",[\"$\",\"h2\",null,{\"children\":\"데이터 생성\"}],\"\\n\",[\"$\",\"h3\",null,{\"children\":\"입출력 형식 정의\"}],\"\\n\",[\"$\",\"p\",null,{\"children\":\"이미 로또 미션을 진행해본 상황으로 입출력 형태의 정의는 잡혀있는 상태이다.\"}],\"\\n\",[\"$\",\"pre\",null,{\"children\":[\"$\",\"code\",null,{\"children\":\"구입금액을 입력해 주세요.\\n8000\\n\\n8개를 구매했습니다.\\n[8, 21, 23, 41, 42, 43]\\n[3, 5, 11, 16, 32, 38]\\n[7, 11, 16, 35, 36, 44]\\n[1, 8, 11, 31, 41, 42]\\n[13, 14, 16, 38, 42, 45]\\n[7, 11, 30, 40, 42, 43]\\n[2, 13, 22, 32, 38, 45]\\n[1, 3, 5, 14, 22, 45]\\n\\n당첨 번호를 입력해 주세요.\\n1,2,3,4,5,6\\n\\n보너스 번호를 입력해 주세요.\\n7\\n\\n당첨 통계\\n---\\n3개 일치 (5,000원) - 1개\\n4개 일치 (50,000원) - 0개\\n5개 일치 (1,500,000원) - 0개\\n5개 일치, 보너스 볼 일치 (30,000,000원) - 0개\\n6개 일치 (2,000,000,000원) - 0개\\n총 수익률은 62.5%입니다.\\n\"}]}],\"\\n\",[\"$\",\"p\",null,{\"children\":\"다만 다음과 같이 입출력이 섞여있는 형태이다.\"}],\"\\n\",[\"$\",\"ol\",null,{\"children\":[\"\\n\",[\"$\",\"li\",null,{\"children\":\"구입금액 입력\"}],\"\\n\",[\"$\",\"li\",null,{\"children\":\"구입갯수 출력\"}],\"\\n\",[\"$\",\"li\",null,{\"children\":\"생성된 번호 출력\"}],\"\\n\",[\"$\",\"li\",null,{\"children\":\"당첨 번호 입력\"}],\"\\n\",[\"$\",\"li\",null,{\"children\":\"...\"}],\"\\n\"]}],\"\\n\",[\"$\",\"p\",null,{\"children\":\"LLM 특성상 인풋 -\u003e 아웃풋으로 출력되기 때문에 입출력의 용이성을 위해 입출력 형식의 개선이 필요했다.\"}],\"\\n\",[\"$\",\"pre\",null,{\"children\":[\"$\",\"code\",null,{\"children\":\"\u003cIN\u003e\\n구입금액={money}\\n당첨번호={w1,w2,w3,w4,w5,w6}\\n보너스번호={bonus}\\n\u003c/IN\u003e\\n###\\n\u003cOUT\u003e\\n티켓수={ticket_count}\\n구매번호:\\n{ticket1}\\n{ticket2}\\n...\\n3개일치={count3}\\n4개일치={count4}\\n5개일치={count5}\\n5개보너스일치={count5b}\\n6개일치={count6}\\n수익률={rate}%\\n\u003c/OUT\u003e\\n\"}]}],\"\\n\",[\"$\",\"p\",null,{\"children\":[\"따라서 다음과 같은 형태로 입출력 형태를 재정의 하였다.\",[\"$\",\"br\",null,{}],\"\\n\",\"또한 ### 구분자를 추가하여 입력과 출력을 구분하였다.\"]}],\"\\n\",[\"$\",\"p\",null,{\"children\":[\"다만 추가 특이사항으로\\n예외에 대한 처리는 데이터 셋에서 제외하였다.\",[\"$\",\"br\",null,{}],\"\\n\",\"학습시간을 최소화하는 것이 가장 큰 관건이라고 생각하였고 가설이 검증될 경우 예외 케이스 추가 및 추가학습으로 예외처리 사항도 가능할 것이라고 예상 했기 때문이다.\"]}],\"\\n\",[\"$\",\"h3\",null,{\"children\":\"데이터 셋은 얼마나 필요할까?\"}],\"\\n\",[\"$\",\"ul\",null,{\"children\":[\"\\n\",[\"$\",\"li\",null,{\"children\":\"디버그/프로토타입용: 5k–10k 샘플\"}],\"\\n\",[\"$\",\"li\",null,{\"children\":\"실험/논문화 가능한 최소선: 20k–50k 샘플\"}],\"\\n\",[\"$\",\"li\",null,{\"children\":\"충분히 안정적인 학습: 50k–100k 샘플\"}],\"\\n\"]}],\"\\n\",[\"$\",\"p\",null,{\"children\":\"정도로 기준점을 마련한 후 가장 작은 단위부터 진행하는 것이\\n학습 시간 고려, 잘못된 데이터셋 개선, 모델 구조 개선 측면에서 좋다고 판단하였다.\"}],\"\\n\",[\"$\",\"p\",null,{\"children\":\"토큰 수를 계산해 보았을때\"}],\"\\n\",[\"$\",\"pre\",null,{\"children\":[\"$\",\"code\",null,{\"children\":\"money=8000            ( ~ 12자 )\\nwinning=1,2,3,4,5,6   ( ~ 20자 )\\nbonus=7               ( ~ 8자 )\\n###                   ( ~ 3자 )\\n티켓수=8              ( ~ 6자 )\\n구매번호:             ( ~ 5자 )\\n[8,21,23,41,42,43]    ( ~ 18자 )  × 티켓수(최대 20개라 쳐도 평균 10개 미만)\\n...\\n3개일치=1             ( ~ 8자 ) × 5줄\\n수익률=62.5%          ( ~ 10자 )\\n\"}]}],\"\\n\",[\"$\",\"p\",null,{\"children\":\"샘플 하나당 200~400글자로 예상하였고\"}],\"\\n\",[\"$\",\"ul\",null,{\"children\":[\"\\n\",[\"$\",\"li\",null,{\"children\":\"10k 샘플 → 약 2M–4M 토큰\"}],\"\\n\",[\"$\",\"li\",null,{\"children\":\"50k 샘플 → 약 10M–20M 토큰\"}],\"\\n\",[\"$\",\"li\",null,{\"children\":\"100k 샘플 → 약 20M–40M 토큰\"}],\"\\n\"]}],\"\\n\",[\"$\",\"p\",null,{\"children\":\"각 샘플당 이러한 토큰 수를 가지게 된다.\"}],\"\\n\",[\"$\",\"hr\",null,{}],\"\\n\",[\"$\",\"h2\",null,{\"children\":\"모델 Pre-training\"}],\"\\n\",[\"$\",\"h4\",null,{\"children\":\"토크나이저 선정\"}],\"\\n\",[\"$\",\"p\",null,{\"children\":[\"기본적으로 많이 사용하는 토크나이저 중 각각 장단점 비교 후 선택하였다.\",[\"$\",\"br\",null,{}],\"\\n\",\"출력에 한국어가 사용되기 때문에 한국어 토크나이저를 기준으로 비교하여 선택하였다.\"]}],\"\\n\",[\"$\",\"ol\",null,{\"children\":[\"\\n\",[\"$\",\"li\",null,{\"children\":[\"\\n\",[\"$\",\"p\",null,{\"children\":[[\"$\",\"strong\",null,{\"children\":\"GPT-2\"}],[\"$\",\"br\",null,{}],\"\\n\",\"한글, 숫자, 기호, 줄바꿈 모두 안정적으로 처리\",[\"$\",\"br\",null,{}],\"\\n\",\"미니 모델 적절한 토큰 수\"]}],\"\\n\"]}],\"\\n\",[\"$\",\"li\",null,{\"children\":[\"\\n\",[\"$\",\"p\",null,{\"children\":[[\"$\",\"strong\",null,{\"children\":\"skt/kogpt2-base-v2\"}],[\"$\",\"br\",null,{}],\"\\n\",\"한국어 SentencePiece 기반 → 한글 처리 매우 안정적\",[\"$\",\"br\",null,{}],\"\\n\",\"vocab_size 약 51k → GPT2와 비슷\"]}],\"\\n\"]}],\"\\n\",[\"$\",\"li\",null,{\"children\":[\"\\n\",[\"$\",\"p\",null,{\"children\":[[\"$\",\"strong\",null,{\"children\":\"EXAONE tokenizer (LGAI-EXAONE/ExaOne-3.5-7.8B-Instruct)\"}],\"\\n한국어 특화에서 가장 좋은 성능을 보임\\nvocab_size 약 500k\"]}],\"\\n\"]}],\"\\n\"]}],\"\\n\",[\"$\",\"p\",null,{\"children\":\"최종적으로는 GPT-2를 그대로 사용하였는데 이유는 다음과 같았다.\"}],\"\\n\",[\"$\",\"ul\",null,{\"children\":[\"\\n\",[\"$\",\"li\",null,{\"children\":[\"GPT-2\",[\"$\",\"br\",null,{}],\"\\n\",\"기존에 만들어봤던 모델에서 사용했기 때문에 시행착오가 적을 것으로 판단\"]}],\"\\n\",[\"$\",\"li\",null,{\"children\":[\"skt/kogpt2-base-v2\",[\"$\",\"br\",null,{}],\"\\n\",\"데이터 셋 특성상 특수 문자 패턴이 반복되는 로또 데이터에서는 GPT2 tokenizer와 큰 차이 없음\",[\"$\",\"br\",null,{}],\"\\n\",\"굳이 가중치가 조금 더 흔들려있는 KoGPT2를 사용해야 할까라는 의문점\"]}],\"\\n\",[\"$\",\"li\",null,{\"children\":[\"EXAONE tokenizer (LGAI-EXAONE/ExaOne-3.5-7.8B-Instruct)\",[\"$\",\"br\",null,{}],\"\\n\",\"vocab_size 약 500k 엄청 큼 → 과도한 vocab 규모라고 판단하여 사용 X\"]}],\"\\n\"]}],\"\\n\",[\"$\",\"h4\",null,{\"children\":\"pad_token 설정\"}],\"\\n\",[\"$\",\"p\",null,{\"children\":\"LLM은 batch 단위로 학습하며 지정한 max_len=256이라면 모든 문장은 길이가 정확히 256토큰이여야한다.\"}],\"\\n\",[\"$\",\"p\",null,{\"children\":\"이전 해리포터 모델과는 다르게 로또 생성기의 경우에는 끝나는 지점이 정해져 있다. 그렇기 때문에 모든 문장의 길이가 동일할 수는 없다.\"}],\"\\n\",[\"$\",\"ul\",null,{\"children\":[\"\\n\",[\"$\",\"li\",null,{\"children\":[\"해리포터 모델\",[\"$\",\"br\",null,{}],\"\\n\",\"Dobby is a가 입력으로 주어지면 책이 끝나는 부분이 아니라면 계속해서 일졍한 부분을 채우게된다.\"]}],\"\\n\",[\"$\",\"li\",null,{\"children\":\"로또 자판기\\n수익률=11.1% 출력되었다면 이 다음에 출력할 부분은 없음\"}],\"\\n\"]}],\"\\n\",[\"$\",\"p\",null,{\"children\":\"따라서 나머지 부분을 채우기 위해 pad_token이란 것을 사용하게 된다.\"}],\"\\n\",[\"$\",\"h4\",null,{\"children\":\"모델 구조 선정\"}],\"\\n\",[\"$\",\"p\",null,{\"children\":\"이 부분에서 많은 내용이 있어야하지만 크게 변경된 사항은 없이 이전 구조를 사용하였다.\"}],\"\\n\",[\"$\",\"p\",null,{\"children\":\"즉, GPT-2 논문 트랜스포머 블록 구조랑 거의 동일하게 사용하였는데\\n아직 추가적인 지식에 대한 학습이 필요한 부분이기도하고, 간단한 모델에서 시작해서 추가적인 사항을 추가하는 것이 중요하다고 판단하였기 때문이였다.\"}],\"\\n\",[\"$\",\"h4\",null,{\"children\":\"학습\"}],\"\\n\",[\"$\",\"p\",null,{\"children\":\"epoch 30으로 진행하였고, RTX 4060을 사용하여 8시간 정도 소요 되었다.\"}],\"\\n\",[\"$\",\"pre\",null,{\"children\":[\"$\",\"code\",null,{\"children\":\"[Epoch 001] train_loss=1.3327, val_loss=0.9760\\n[Epoch 002] train_loss=1.1994, val_loss=0.9647\\n[Epoch 003] train_loss=1.0896, val_loss=0.9421\\n...\\n[Epoch 028] train_loss=0.7817, val_loss=0.7795\\n[Epoch 029] train_loss=0.7805, val_loss=0.7783\\n[Epoch 030] train_loss=0.7798, val_loss=0.7781\\n\"}]}],\"\\n\",[\"$\",\"p\",null,{\"children\":\"loss 또한 꾸준히 하락하였고 과적합 또한 보이지 않았다.\"}],\"\\n\",[\"$\",\"h4\",null,{\"children\":\"결과\"}],\"\\n\",[\"$\",\"img\",null,{\"src\":\"/images/LLM/result1-1.png\",\"width\":\"100%\",\"height\":\"100%\"}],\"\\n\",[\"$\",\"img\",null,{\"src\":\"/images/LLM/result1-2.png\",\"width\":\"100%\",\"height\":\"100%\"}],\"\\n\",[\"$\",\"p\",null,{\"children\":\"어느 정도 형태를 띄는 긍정적인 결과값을 확인할 수 있었다 !!\"}],\"\\n\",[\"$\",\"p\",null,{\"children\":\"입력된 금액을 바탕으로\\n티켓수, 구매번호를 갯수에 맞게 출력했고 n개 일치 항목, 수익률 항목에 대해 형식을 잘 출력하는 것을 볼 수 있다.\"}],\"\\n\",[\"$\",\"hr\",null,{}],\"\\n\",[\"$\",\"h2\",null,{\"children\":\"n차 개선 학습\"}],\"\\n\",[\"$\",\"h3\",null,{\"children\":\"1차 모델 개선\"}],\"\\n\",[\"$\",\"h4\",null,{\"children\":\"1. repetition loop\"}],\"\\n\",[\"$\",\"p\",null,{\"children\":\"수익률 부분에서 출력값이 이상한 것을 확인할 수 있었다.\"}],\"\\n\",[\"$\",\"p\",null,{\"children\":[\"$\",\"strong\",null,{\"children\":\"수익률 =0.0%%%%%%%%%%%%%%%\"}]}],\"\\n\",[\"$\",\"p\",null,{\"children\":\"마지막에 %이 계속해서 반복되며 출력되는 현상으로 멈춰야하는 신호를 주지않았기 때문에 발생한 문제\"}],\"\\n\",[\"$\",\"p\",null,{\"children\":\"멈춤 신호인 EOS토큰을 stop 조건으로 안쓰지 않았고 학습과정에서 eos 토큰을 따로 붙여준 적이 없었기 때문에\\n데이터셋을 로드하는 LottoDataset 객체를 수정하여 마지막에 eos토큰이 추가되도록 수정하였다.\"}],\"\\n\",[\"$\",\"p\",null,{\"children\":\"(EOS 토큰 부분에서 모델학습만 3~4번 반복하였는데 기존 코드를 삭제하지 않아 누락되었던 것은 비밀...)\"}],\"\\n\",[\"$\",\"h4\",null,{\"children\":\"2. 출력값 제한으로 인한 짤림 문제\"}],\"\\n\",[\"$\",\"p\",null,{\"children\":\"max_len을 256으로 설정하여 진행하였는데 입력 금액이 많아질 경우 출력 토큰 제한으로 출력이 짤리는 문제가 발생하였다.\"}],\"\\n\",[\"$\",\"pre\",null,{\"children\":[\"$\",\"code\",null,{\"children\":\"money=18000\\nwinning=1,2,3,4,5,6\\n...\\n[4,20,22,32,39,40]\\n[11,13,20\\n\"}]}],\"\\n\",[\"$\",\"p\",null,{\"children\":[\"이런식으로 마지막 부분이 짤려 정상적인 출력이 되지않는 상황이였다.\",[\"$\",\"br\",null,{}],\"\\n\",\"max_len은 학습시간과 연관이 있어 무제한으로 키우기는 어려우니 최소 상한 금액을 20000원으로 가정하고\\nmax_len을 512로 수정하여 진행하였다.\"]}],\"\\n\",[\"$\",\"p\",null,{\"children\":[\"max_len=256\",[\"$\",\"br\",null,{}],\"\\n\",\"→ 총 토큰 = 10,000 × 256 = 2.56M tokens\"]}],\"\\n\",[\"$\",\"p\",null,{\"children\":[\"max_len=512\",[\"$\",\"br\",null,{}],\"\\n\",\"→ 총 토큰 = 10,000 × 512 = 5.12M tokens\"]}],\"\\n\",[\"$\",\"p\",null,{\"children\":\"토큰 수 변화가 2배로 뛰게 되었다.\"}],\"\\n\",[\"$\",\"h4\",null,{\"children\":\"2-1. 출력값 증가로 인한 메모리 부족현상 발생\"}],\"\\n\",[\"$\",\"p\",null,{\"children\":\"출력값이 두배로 뛰면서 input으로 사용되는 데이터 크기 또한 두배로 커졌고 이에 따라 GPU의 메모리에서 OOM이 발생하는 현상이 발생하였다.\"}],\"\\n\",[\"$\",\"p\",null,{\"children\":\"GPU 메모리 한계를 극복하기 위해 Gradient Accumulation를 적용하여 자원의 한계를 해결하고자 하였다.\"}],\"\\n\",[\"$\",\"p\",null,{\"children\":\"Gradient Accumulation는 간단하게 기존 배치를 작은 배치(학습단위)로 줄인 후 작은 배치에서 계산된 loss를 누적하여\\n정해진 횟수에 도달할 경우 그때 가중치를 업데이트하는 방식이다.\"}],\"\\n\",[\"$\",\"p\",null,{\"children\":[\"기존 batch size = 32 -\u003e batch size = 8, accum_steps = 4로 수정하여\",[\"$\",\"br\",null,{}],\"\\n\",\"(batch 8 * 4 = effective 32) 기존의 32 batch와 동일한 효과를 낼 수 있도록 수정하였다.\"]}],\"\\n\",[\"$\",\"h3\",null,{\"children\":\"2차 모델 개선\"}],\"\\n\",[\"$\",\"p\",null,{\"children\":\"2차 부터는 각 기능이 제대로 동작하는가를 체크하였다.\"}],\"\\n\",[\"$\",\"h4\",null,{\"children\":\"1. 당첨번호 계산 과적합 문제 해결\"}],\"\\n\",[\"$\",\"pre\",null,{\"children\":[\"$\",\"code\",null,{\"children\":\"money=5000\\nwinning=1,2,3,4,5,6\\nbonus=7\\n...\\n[4,5,6,25,27,44]\\n3개일치=0\\n\"}]}],\"\\n\",[\"$\",\"p\",null,{\"children\":\"n개 일치 항목에 대해 카운트가 잘 되지않는 현상이였다.\\n모든 간이 테스트에서 일치하는 항목이 나오지 않았다.\"}],\"\\n\",[\"$\",\"p\",null,{\"children\":[\"로또의 확률을 생각해보면 그 답을 알 수 있었는데, 로또 번호는 기본적으로 당첨 확률이 굉장히 낮은 분포를 보인다.\",[\"$\",\"br\",null,{}],\"\\n\",\"이 때문에 n개 일치 항목에 대한 데이터셋에는 일치 항목이 0인 데이터셋이 많아지게된다.\"]}],\"\\n\",[\"$\",\"p\",null,{\"children\":[\"즉 많은 데이터가 일치항목에서 0을 띄기 때문에 gpt는 해당 패턴을 기준으로 0이 정답이라는 기준을 세우게 되는 것이다.\\n(값이 있더라도 loss가 낮기 때문에 해당 부분이 무시되게됨)\",[\"$\",\"br\",null,{}],\"\\n\",\"일치 항목에 대해서 0에 과적합이 되는 것이다.\"]}],\"\\n\",[\"$\",\"p\",null,{\"children\":\"이를 해결하기 위해 데이터셋 생성 부분에서 일정한 비율로 당첨번호가 꼭 나오도록 생성에 대한 조건을 추가하여 학습하였다.\"}],\"\\n\",[\"$\",\"pre\",null,{\"children\":[\"$\",\"code\",null,{\"children\":\"FORCE_HIT_PROB = 0.3 # 당첨 비율 설정(30%)\\nif random.random() \u003c FORCE_HIT_PROB and ticket_count \u003e 0:\\n    # 어떤 등수를 넣을지 가중치로 선택\\n    rank_candidates = [\\\"3\\\", \\\"4\\\", \\\"5\\\", \\\"5b\\\", \\\"6\\\"]\\n    # 3개/4개 정도를 많이, 5/5b/6은 조금만\\n    rank_weights = [0.4, 0.2, 0.2, 0.1, 0.1]\\n    rank = random.choices(rank_candidates, weights=rank_weights, k=1)[0]\\n\\n    # 티켓 중 하나 골라서 그 자리를 \\\"해당 등수 티켓\\\"으로 바꿈\\n    idx = random.randrange(ticket_count)\\n    tickets[idx] = generate_ticket_with_rank(winning, bonus, rank)\\n\"}]}],\"\\n\",[\"$\",\"h4\",null,{\"children\":\"2. 수익률 부분 추가 데이터 제공\"}],\"\\n\",[\"$\",\"p\",null,{\"children\":\"수익률 또한 높은 확률로 계산하지 못하였는데 너무나 근거없는 수치가 나오는 경우의 수가 많았다.\"}],\"\\n\",[\"$\",\"p\",null,{\"children\":\"데이터 셋을 확인하였을때 수익률 계산에 대한 근거가 부족하다는 생각이 들었다.\"}],\"\\n\",[\"$\",\"pre\",null,{\"children\":[\"$\",\"code\",null,{\"children\":\"3개일치={count3}\\n4개일치={count4}\\n5개일치={count5}\\n5개보너스일치={count5b}\\n6개일치={count6}\\n수익률={rate}%\\n\"}]}],\"\\n\",[\"$\",\"p\",null,{\"children\":[\"지금 형태는 이런 형태인데 n개 일치에 따라서 따라오는 금액이 얼마인지 데이터셋에서 찾기 힘들었다.\",[\"$\",\"br\",null,{}],\"\\n\",\"따라서 일치시 얻게되는 금액을 추가하여 gpt가 해당 금액을 계산(패턴학습)할 수 있도록 추가하였다.\"]}],\"\\n\",[\"$\",\"pre\",null,{\"children\":[\"$\",\"code\",null,{\"children\":\"3개일치 (5000원) = 0\\n4개일치 (50000원) = 0\\n5개일치 (1500000원) = 0\\n5개보너스일치 (30000000원) = 0\\n6개일치 (2000000000원) = 0\\n수익률=0.0%\\n\"}]}],\"\\n\",[\"$\",\"h3\",null,{\"children\":\"3차 모델 개선\"}],\"\\n\",[\"$\",\"p\",null,{\"children\":\"수익률 부분에서는 높은 일치율을 보였지만 당첨번호 계산 부분에서는 아직도 낮은 일치율을 보였다.\"}],\"\\n\",[\"$\",\"p\",null,{\"children\":[[\"$\",\"strong\",null,{\"children\":\"Task-Aware Weighted Loss\"}],\", \",[\"$\",\"strong\",null,{\"children\":\"Token-level Weighting\"}],\",\",[\"$\",\"strong\",null,{\"children\":\"Curriculum by Masking\"}],\"\\n으로 불리는 어려운 부분에 가중치를 더욱 크게 부여하는 것이 해결책으로 판단하였다.\"]}],\"\\n\",[\"$\",\"p\",null,{\"children\":\"즉 loss를 보았을때 감소하는 추세이나 모든 토큰이 똑같이 1.0의 가중치로 loss에 들어가기 떄문에\\n똑같은 가중치로 하였을때 정해져있는 포맷부분(money=, winning=, 숫자 쉼표, 티켓수= 등)은 잘맞추어 loss가 떨어지고\\n마지막인 당첨갯수, 수익률 부분은 대충 때려맞추고 있어도 loss에 반영되지 않은 현상이 발생하는 것으로 예상하였다.\"}],\"\\n\",[\"$\",\"p\",null,{\"children\":\"따라서 모델 구성을 변경하여 마지막 tail_len을 계산후 지정하여 해당 부분이 더 높은 가중치를 가지도록 변경하였다.\"}],\"\\n\",[\"$\",\"h3\",null,{\"children\":\"4차 모델 개선\"}],\"\\n\",[\"$\",\"p\",null,{\"children\":\"당첨번호 계산 부분에서 추가적인 효과가 없어 데이터 셋의 크기를 늘려 추가적인 학습이 반영되도록 개선하였다.\"}],\"\\n\",[\"$\",\"ul\",null,{\"children\":[\"\\n\",[\"$\",\"li\",null,{\"children\":\"10k 샘플 → 약 2M–4M 토큰\"}],\"\\n\",[\"$\",\"li\",null,{\"children\":\"50k 샘플 → 약 10M–20M 토큰\"}],\"\\n\",[\"$\",\"li\",null,{\"children\":\"150k 샘플 → 약 40M–60M 토큰\"}],\"\\n\"]}],\"\\n\",[\"$\",\"p\",null,{\"children\":\"학습량을 지속적으로 늘려 진행했고 그 과정 속에서 기능이 동작하는지 확인하였으나 큰 효과를 얻기는 어려웠다.\"}],\"\\n\",[\"$\",\"hr\",null,{}],\"\\n\",[\"$\",\"h2\",null,{\"children\":\"모델 테스트\"}],\"\\n\",[\"$\",\"h3\",null,{\"children\":\"테스트 정의\"}],\"\\n\",[\"$\",\"p\",null,{\"children\":\"기존 LLm을 테스트하기 위해 여러 방법이 있는 것으로 알고 있다.\"}],\"\\n\",[\"$\",\"ul\",null,{\"children\":[\"\\n\",[\"$\",\"li\",null,{\"children\":\"MMLU\"}],\"\\n\",[\"$\",\"li\",null,{\"children\":\"KMMLU\"}],\"\\n\",[\"$\",\"li\",null,{\"children\":\"HAERAE\"}],\"\\n\",[\"$\",\"li\",null,{\"children\":\"HumanEval\"}],\"\\n\",[\"$\",\"li\",null,{\"children\":\"MBPP\"}],\"\\n\",[\"$\",\"li\",null,{\"children\":\"GSM8K\"}],\"\\n\"]}],\"\\n\",[\"$\",\"p\",null,{\"children\":\"다만 프로그래밍적인 요소, 출력 형태의 고정으로 새로운 테스트를 정의해야한다고 생각하였다.\"}],\"\\n\",[\"$\",\"p\",null,{\"children\":\"출력한 형태와 기능을 만족하는가 두가지를 기준으로 테스트 기준을 재설정하였다.\"}],\"\\n\",[\"$\",\"h4\",null,{\"children\":\"1. 형식/파싱 레벨\"}],\"\\n\",[\"$\",\"p\",null,{\"children\":[\"$\",\"strong\",null,{\"children\":\"1-1. 티켓수 형식\"}]}],\"\\n\",[\"$\",\"ul\",null,{\"children\":[\"\\n\",[\"$\",\"li\",null,{\"children\":\"티켓수 = N 이 존재하는지\"}],\"\\n\",[\"$\",\"li\",null,{\"children\":\"N이 정수로 파싱되는지\"}],\"\\n\"]}],\"\\n\",[\"$\",\"p\",null,{\"children\":[\"$\",\"strong\",null,{\"children\":\"1-2. 구매번호 줄 형식\"}]}],\"\\n\",[\"$\",\"ul\",null,{\"children\":[\"\\n\",[\"$\",\"li\",null,{\"children\":\"구매번호: 라인이 존재하는지\"}],\"\\n\",[\"$\",\"li\",null,{\"children\":\"그 아래에 [...] 형태의 줄들이 있는지\"}],\"\\n\",[\"$\",\"li\",null,{\"children\":\"각 줄에서 숫자를 파싱할 수 있는지\"}],\"\\n\"]}],\"\\n\",[\"$\",\"p\",null,{\"children\":[\"$\",\"strong\",null,{\"children\":\"1-3. 라벨(결과) 줄 형식\"}]}],\"\\n\",[\"$\",\"ul\",null,{\"children\":[\"\\n\",[\"$\",\"li\",null,{\"children\":[\"아래 항목이 모두 존재하고 숫자로 파싱되는지\",\"\\n\",[\"$\",\"ul\",null,{\"children\":[\"\\n\",[\"$\",\"li\",null,{\"children\":\"3개일치 (...) = X\"}],\"\\n\",[\"$\",\"li\",null,{\"children\":\"4개일치 (...) = Y\"}],\"\\n\",[\"$\",\"li\",null,{\"children\":\"5개일치 (...) = Z\"}],\"\\n\",[\"$\",\"li\",null,{\"children\":\"5개보너스일치 (...) = A\"}],\"\\n\",[\"$\",\"li\",null,{\"children\":\"6개일치 (...) = B\"}],\"\\n\",[\"$\",\"li\",null,{\"children\":\"수익률 = R%\"}],\"\\n\"]}],\"\\n\"]}],\"\\n\"]}],\"\\n\",[\"$\",\"h4\",null,{\"children\":\"2. 내부 일관성 레벨\"}],\"\\n\",[\"$\",\"p\",null,{\"children\":[\"$\",\"strong\",null,{\"children\":\"2-1. 티켓수 일관성\"}]}],\"\\n\",[\"$\",\"ul\",null,{\"children\":[\"\\n\",[\"$\",\"li\",null,{\"children\":\"티켓수 = 실제 구매번호 줄 개수가 같은지\"}],\"\\n\"]}],\"\\n\",[\"$\",\"p\",null,{\"children\":[\"$\",\"strong\",null,{\"children\":\"2-2. 구매번호 자체 유효성\"}]}],\"\\n\",[\"$\",\"ul\",null,{\"children\":[\"\\n\",[\"$\",\"li\",null,{\"children\":\"각 줄에 숫자가 정확히 6개인지\"}],\"\\n\",[\"$\",\"li\",null,{\"children\":\"한 줄 안에 중복 숫자가 없는지\"}],\"\\n\",[\"$\",\"li\",null,{\"children\":\"각 숫자가 1~45 범위인지\"}],\"\\n\"]}],\"\\n\",[\"$\",\"h2\",null,{\"children\":\"3. 계산 정확도 레벨 (기능 테스트)\"}],\"\\n\",[\"$\",\"p\",null,{\"children\":\"LLM 출력에 적힌 “결과 값들”이, 그 LLM이 출력한 “구매번호”로 실제 계산했을 때 맞는지.\"}],\"\\n\",[\"$\",\"p\",null,{\"children\":[\"$\",\"strong\",null,{\"children\":\"3-1. n개 일치 수 계산 검증\"}]}],\"\\n\",[\"$\",\"ul\",null,{\"children\":[\"\\n\",[\"$\",\"li\",null,{\"children\":\"구매번호 기반으로 다시 3/4/5/5b/6개 일치 개수를 계산\"}],\"\\n\",[\"$\",\"li\",null,{\"children\":\"그 값이 LLM이 쓴 X, Y, Z, A, B와 각각 일치하는지\"}],\"\\n\"]}],\"\\n\",[\"$\",\"p\",null,{\"children\":[\"$\",\"strong\",null,{\"children\":\"3-2. 수익률 계산 검증\"}]}],\"\\n\",[\"$\",\"ul\",null,{\"children\":[\"\\n\",[\"$\",\"li\",null,{\"children\":\"이 값이 LLM이 쓴 수익률 = 실제 수익율\"}],\"\\n\"]}],\"\\n\",[\"$\",\"h3\",null,{\"children\":\"테스트 결과\"}],\"\\n\",[\"$\",\"pre\",null,{\"children\":[\"$\",\"code\",null,{\"children\":\"=== TEST SUMMARY ===\\nn_total : 5000\\nn_ok : 2298 (성공)\\nn_fail : 2702 (실패)\\n\\nn_format_fail : 293 (형식표현 실패)\\nn_logic_fail : 2409 (기능구현 실패)\\n\\nticket_count_parse_error : 0\\nticket_lines_format_error : 2\\nresult_labels_parse_error : 11\\nticket_count_mismatch : 35\\nticket_numbers_invalid : 245\\n\\nmatch_stats_mismatch : 2408\\nroi_mismatch : 17\\ntest_fail : 0\\n\"}]}],\"\\n\",[\"$\",\"h4\",null,{\"children\":\"출력 형식 오류 분석\"}],\"\\n\",[\"$\",\"p\",null,{\"children\":[\"n_format_fail : 텍스트 출력 구조 문제\",[\"$\",\"br\",null,{}],\"\\n\",\"5000중 293건 → 형식 안정도 94%\"]}],\"\\n\",[\"$\",\"p\",null,{\"children\":[[\"$\",\"code\",null,{\"children\":\"n_format_fail\"}],\"에러 항목\"]}],\"\\n\",[\"$\",\"ul\",null,{\"children\":[\"\\n\",[\"$\",\"li\",null,{\"children\":[\"ticket_count_parse_error\",[\"$\",\"br\",null,{}],\"\\n\",[\"$\",\"code\",null,{\"children\":\"티켓:숫자\"}],\" 항목이 형식대로 출력되는가\"]}],\"\\n\",[\"$\",\"li\",null,{\"children\":[\"ticket_lines_format_error\",[\"$\",\"br\",null,{}],\"\\n\",[\"$\",\"code\",null,{\"children\":\"구매번호:\"}],\" 라인이 존재하는지\\n하위의 \",[\"$\",\"code\",null,{\"children\":\"구매번호: [:]\"}],\" 생선된 구매번호 형식에 맞게 출력되었는지\"]}],\"\\n\",[\"$\",\"li\",null,{\"children\":[\"result_labels_parse_error\",[\"$\",\"br\",null,{}],\"\\n\",[\"$\",\"code\",null,{\"children\":\"n개일치: ~ 수익률:\"}],\"의 항목이 형식대로 출력되는가\"]}],\"\\n\",[\"$\",\"li\",null,{\"children\":[\"ticket_count_mismatch\\n\",[\"$\",\"code\",null,{\"children\":\"구매한티켓수 = 구매번호의 티켓수\"}],\" , 실제로 금액만큼 티켓을 구매하였는가\"]}],\"\\n\",[\"$\",\"li\",null,{\"children\":[\"ticket_numbers_invalid\\n\",[\"$\",\"code\",null,{\"children\":\"구매번호\"}],\"가 올바른 형식인가(중복 X, 1~45)\"]}],\"\\n\"]}],\"\\n\",[\"$\",\"p\",null,{\"children\":\"각 항목에서 발생된 결과는 다음과 같다.\"}],\"\\n\",[\"$\",\"ul\",null,{\"children\":[\"\\n\",[\"$\",\"li\",null,{\"children\":\"format_fail : 293건, 5.86%\"}],\"\\n\",[\"$\",\"li\",null,{\"children\":\"lines error : 2건, 0.04%\"}],\"\\n\",[\"$\",\"li\",null,{\"children\":\"label parse error : 11건,\\t0.22%\"}],\"\\n\",[\"$\",\"li\",null,{\"children\":\"ticket_count_mismatch\\t: 35건, 0.70%\"}],\"\\n\",[\"$\",\"li\",null,{\"children\":\"ticket_numbers_invalid : 245건, 4.90%\"}],\"\\n\"]}],\"\\n\",[\"$\",\"h4\",null,{\"children\":\"기능 구현 오류 분석\"}],\"\\n\",[\"$\",\"p\",null,{\"children\":\"n_logic_fail : 기능 구현 오류\\n5000중 2409건 → 안정도 55%\"}],\"\\n\",[\"$\",\"p\",null,{\"children\":[\"match_stats_mismatch : 2408\",[\"$\",\"br\",null,{}],\"\\n\",\"그중 당첨번호 일치가 대분을 차지하는 모습을 보였음\"]}],\"\\n\",[\"$\",\"p\",null,{\"children\":\"n_logic_fail ≈ match_stats_mismatch 인 상황으로 수익률 부분 계산 부분은 0.34% 에러율을 보이며 매우 낮은 수치를\"}],\"\\n\",[\"$\",\"p\",null,{\"children\":\"출력 포맷의 안정성과 수익률 수치 예측은 높은 정확도를 보였으나, 집합 비교 기반 연산 문제에서는 기능 구현 부분에서의 한계를 확인할 수 있었다.\"}]]]}],null],\"segment\":\"__PAGE__?{\\\"slug\\\":\\\"LLMgpt2\\\"}\"},\"styles\":[]}],\"segment\":[\"slug\",\"LLMgpt2\",\"d\"]},\"styles\":[]}],\"segment\":\"blog\"},\"styles\":[]}]}],[\"$\",\"footer\",null,{\"className\":\"w-full max-w-3xl items-center \",\"children\":[[\"$\",\"div\",null,{\"className\":\"h-28\"}],\" \"]}]]}]]}]]}],null]}]]\n"])</script><script>self.__next_f.push([1,"5:[[\"$\",\"meta\",\"0\",{\"charSet\":\"utf-8\"}],[\"$\",\"title\",\"1\",{\"children\":\"GPT은 직접 사드세요... 제발 - GPT 2\"}],[\"$\",\"meta\",\"2\",{\"name\":\"description\",\"content\":\"로또 번호 자판기 모델 구현, 학습, 결과\"}],[\"$\",\"meta\",\"3\",{\"name\":\"viewport\",\"content\":\"width=device-width, initial-scale=1\"}],[\"$\",\"meta\",\"4\",{\"name\":\"google-site-verification\",\"content\":\"LXzAKbA2-HVF1l60gXdTElFNxVVLxh1rk6qwe1V41so\"}],[\"$\",\"link\",\"5\",{\"rel\":\"icon\",\"href\":\"/favicon.ico\",\"type\":\"image/x-icon\",\"sizes\":\"16x16\"}],[\"$\",\"meta\",\"6\",{\"name\":\"next-size-adjust\"}]]\n"])</script><script>self.__next_f.push([1,"b:null\n"])</script></body></html>